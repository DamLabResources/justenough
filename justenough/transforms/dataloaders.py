# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/12_transforms.dataloaders.ipynb (unless otherwise specified).

__all__ = ['HFBertDataLoaders']

# Cell

from fastai.text.all import *


from .sequence import *

# Cell

# export


class HFBertDataLoaders(DataLoaders):

    @staticmethod
    def from_df(frame, tokenizer, model, sequence_col = 'sequence', label_col = None, vocab=None,
                max_length = 128, device = 'cuda', bs = 32, precompute = True,
                splitter = None, num_workers = 0):

        if splitter is None:
            splitter = RandomSplitter()


        seq_tfms = [ColReader(sequence_col),
                    SpaceTransform(),
                    HFTokenizerWrapper(tokenizer,
                                       max_length=max_length,
                                       tokens_only=False,
                                       device = device),
                    HFPoolingTransform(model, bs=bs)]
        if label_col is None:
            label_tfms = seq_tfms
        else:
            label_tfms = [ColReader(label_col), Categorize(vocab=vocab)]


        if precompute:

            seq_pipe = Pipeline(seq_tfms)
            seq_tls = seq_pipe(frame)

            if label_col is None:
                label_tls = seq_tls
            else:
                label_tls = TfmdLists(frame, label_tfms)

            tls = TfmdLists(zip(seq_tls, label_tls), [])
            train, test = splitter(tls)

            return DataLoaders.from_dsets(tls[train], tls[test], num_workers=0, bs=bs).to(device)


        else:

            train, test = splitter(frame)
            feat_tls = Datasets(frame, [seq_tfms, label_tfms],
                               splits = (train, test))

            dls = feat_tls.dataloaders(num_workers=0, bs=bs).to(device)

            return dls