{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp glp.prediction\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glp.clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from umap import UMAP\n",
    "from fastai.text.all import *\n",
    "import hdbscan\n",
    "\n",
    "from justenough.nlp.core import *\n",
    "from justenough.explain.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "For this example we're going to use a small dataset of 2000 HIV tat proteins with labels for tissue of isolation and co-receptor binding.\n",
    "We'll see if the clusters generated by topic modeling will correspond to these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>sample_tissue</th>\n",
       "      <th>coreceptor</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M17449</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CXCR4</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTACTTCYCKKCCFHCQVCFTKKALGISYGRKKRRQRRRAPEDSQTHQVSLPKQPAPQFRGDPTGPKESKKKVERETETHPVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M26727</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTASNNCYCKRCCLHCQVCFTKKGLGISYGRKKRRQRRRAPQDSKTHQVSLSKQPASQPRGDPTGPKESKKKVERETETDPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M17451</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5|CXCR4</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTACNNCYCKKCCYHCQVCFLTKGLGISYGRKKRRQRRGPPQGSQTHQVSLSKQPTSQPRGDPTGPKESKEKVERETETDPAVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K02007</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5|CXCR4</td>\n",
       "      <td>MEPVDPNLEPWKHPGSQPRTACNNCYCKKCCFHCYACFTRKGLGISYGRKKRRQRRRAPQDSQTHQASLSKQPASQSRGDPTGPTESKKKVERETETDPFD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M62320</td>\n",
       "      <td>blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEPVDPNLEPWKHPGSQPTTACSNCYCKVCCWHCQLCFLKKGLGISYGKKKRKPRRGPPQGSKDHQTLIPKQPLPQSQRVSAGQEESKKKVESKAKTDRFA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession sample_tissue  coreceptor  \\\n",
       "0    M17449          PBMC       CXCR4   \n",
       "1    M26727          PBMC        CCR5   \n",
       "2    M17451          PBMC  CCR5|CXCR4   \n",
       "3    K02007          PBMC  CCR5|CXCR4   \n",
       "4    M62320         blood         NaN   \n",
       "\n",
       "                                                                                                 sequence  \n",
       "0   MEPVDPRLEPWKHPGSQPKTACTTCYCKKCCFHCQVCFTKKALGISYGRKKRRQRRRAPEDSQTHQVSLPKQPAPQFRGDPTGPKESKKKVERETETHPVD  \n",
       "1   MEPVDPRLEPWKHPGSQPKTASNNCYCKRCCLHCQVCFTKKGLGISYGRKKRRQRRRAPQDSKTHQVSLSKQPASQPRGDPTGPKESKKKVERETETDPED  \n",
       "2  MEPVDPRLEPWKHPGSQPKTACNNCYCKKCCYHCQVCFLTKGLGISYGRKKRRQRRGPPQGSQTHQVSLSKQPTSQPRGDPTGPKESKEKVERETETDPAVQ  \n",
       "3   MEPVDPNLEPWKHPGSQPRTACNNCYCKKCCFHCYACFTRKGLGISYGRKKRRQRRRAPQDSQTHQASLSKQPASQSRGDPTGPTESKKKVERETETDPFD  \n",
       "4   MEPVDPNLEPWKHPGSQPTTACSNCYCKVCCWHCQLCFLKKGLGISYGKKKRKPRRGPPQGSKDHQTLIPKQPLPQSQRVSAGQEESKKKVESKAKTDRFA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../tutorials/HIV_tat_example.csv').dropna(subset = ['sample_tissue'])\n",
    "df['sequence'] = df['sequence'].str.strip('*')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Rostlab/prot_bert'\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the HuggingFace tokenizer we need to add spaces between all of the AAs in our sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def space_adder(seq):\n",
    "    \n",
    "    return ' '.join(seq)\n",
    "\n",
    "\n",
    "class SpaceTransform(Transform):\n",
    "    \"\"\"Adds spaces between AAs for HuggingFace\"\"\"\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        if type(x) == str:\n",
    "            x = [x]\n",
    "        return L(space_adder(seq) for seq in x)\n",
    "    \n",
    "    def decodes(self, x):\n",
    "        \n",
    "        return [seq.replace(' ', '') for seq in x]\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(space_adder('MIVLR'), 'M I V L R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "space_tfm = SpaceTransform()\n",
    "\n",
    "pipe = Pipeline([space_tfm])\n",
    "\n",
    "tst = ['MIVLR', 'AAR']\n",
    "cor = ['M I V L R', 'A A R']\n",
    "\n",
    "test_eq(pipe(tst), cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to pass them through the Huggingface Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "class HFTokenizerWrapper(Transform):\n",
    "    \n",
    "    def __init__(self, tokenizer, tokens_only = True, \n",
    "                 truncation = True, max_length = 128,\n",
    "                 padding = 'max_length', \n",
    "                 skip_special_tokens = True,\n",
    "                 device = 'cuda'): \n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokens_only = tokens_only\n",
    "        self.truncation = truncation\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.skip_special_tokens = skip_special_tokens\n",
    "        self.device = device\n",
    "        \n",
    "    def encodes(self, x):\n",
    "        \n",
    "        if type(x) == str:\n",
    "            x = [x]\n",
    "            \n",
    "        tokenized = self.tokenizer(list(x), \n",
    "                                   return_tensors='pt', \n",
    "                                   padding=self.padding,\n",
    "                                   truncation = self.truncation,\n",
    "                                   max_length = self.max_length)\n",
    "        tokenized = tokenized.to(self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.tokens_only:\n",
    "            return tokenized['input_ids']\n",
    "        else:\n",
    "            return [fastuple(tokenized['input_ids'][i], tokenized['attention_mask'][i]) for i in range(len(x))]\n",
    "        \n",
    "        \n",
    "    def decodes(self, x):\n",
    "        \n",
    "        return self.tokenizer.batch_decode(x, skip_special_tokens = self.skip_special_tokens)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_tfm = SpaceTransform()\n",
    "token_tfm = HFTokenizerWrapper(tokenizer, max_length=7, device = 'cpu')\n",
    "pipe = Pipeline([space_tfm, token_tfm])\n",
    "\n",
    "tst = ['MIVLR', 'AAR']\n",
    "cor = [[2, 21, 11,  8, 5, 13, 3], \n",
    "       [2,  6,  6, 13, 3,  0, 0]]\n",
    "\n",
    "test_eq(pipe(tst), tensor(cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pipe.decode(tensor(cor)), tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([ 2, 21, 11,  8,  5,  3]), tensor([1, 1, 1, 1, 1, 1])),\n",
       " (tensor([ 2,  6,  6, 13,  3,  0]), tensor([1, 1, 1, 1, 1, 0]))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_tfm = HFTokenizerWrapper(tokenizer, max_length=6, tokens_only=False, device = 'cpu')\n",
    "pipe = Pipeline([space_tfm, token_tfm])\n",
    "pipe(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the tokenized tensors, we can feed them into the model and get their encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "\n",
    "\n",
    "class HFPoolingTransform(Transform):\n",
    "    \n",
    "    def __init__(self, model, batch_size = 32, progress = False):\n",
    "        \n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.progress = progress\n",
    "    \n",
    "    def encodes(self, x):\n",
    "        \n",
    "        if type(x[0]) == fastuple:\n",
    "            input_ids, attention = zip(*x)\n",
    "            input_ids = torch.vstack(input_ids)\n",
    "            attention = torch.vstack(attention).type(torch.bool)\n",
    "        else:\n",
    "            input_ids = x\n",
    "            attention = x != 0\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            if self.batch_size is not None:\n",
    "                #print(input_ids.shape)\n",
    "                out = []\n",
    "                if self.progress:\n",
    "                    it = progress_bar(range(0, input_ids.shape[0], self.batch_size))\n",
    "                else:\n",
    "                    it = range(0, input_ids.shape[0], self.batch_size)\n",
    "                for start in it:            \n",
    "                    res = self.model(input_ids = input_ids[start:start+self.batch_size],\n",
    "                                     attention_mask = attention[start:start+self.batch_size])\n",
    "                    out.append(masked_concat_pool(res[0], attention[start:start+self.batch_size], input_ids.shape[1]-1))\n",
    "                return torch.vstack(out)\n",
    "            else:\n",
    "                res = self.model(input_ids = input_ids,\n",
    "                                 attention_mask = attention)\n",
    "                return masked_concat_pool(res[0], attention, \n",
    "                                          input_ids.shape[1]-1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_tfm = HFTokenizerWrapper(tokenizer, max_length=6, tokens_only=True, device = 'cuda')\n",
    "bert_pool_tfm = HFPoolingTransform(model)\n",
    "pipe = Pipeline([space_tfm, token_tfm, bert_pool_tfm])\n",
    "\n",
    "encoded = pipe(tst*100)\n",
    "\n",
    "test_eq(encoded.shape, (200, 3072))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to make our future lives easier, lets encapsulate all of this into a `Dataloders` subclass.\n",
    "\n",
    "This one can take a dataframe and some parameters and intelligently construct the dataloaders. Allowing for pre-computing and easy setup with autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HFBertDataLoaders(DataLoaders):\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_df(frame, tokenizer, model, sequence_col = 'sequence', label_col = None, vocab=None,\n",
    "                max_length = 128, device = 'cuda', bs = 32, precompute = True,\n",
    "                splitter = None, num_workers = 0):\n",
    "        \n",
    "        if splitter is None:\n",
    "            splitter = RandomSplitter()\n",
    "            \n",
    "            \n",
    "        seq_tfms = [ColReader(sequence_col),\n",
    "                    SpaceTransform(),\n",
    "                    HFTokenizerWrapper(tokenizer, \n",
    "                                       max_length=max_length, \n",
    "                                       tokens_only=False, \n",
    "                                       device = device),\n",
    "                    HFPoolingTransform(model,batch_size=bs)]\n",
    "        if label_col is None:\n",
    "            label_tfms = seq_tfms\n",
    "        else:\n",
    "            label_tfms = [ColReader(label_col), Categorize(vocab=vocab)]\n",
    "            \n",
    "        \n",
    "        if precompute:\n",
    "            \n",
    "            seq_pipe = Pipeline(seq_tfms)\n",
    "            seq_tls = seq_pipe(frame)\n",
    "            \n",
    "            if label_col is None:\n",
    "                label_tls = seq_tls\n",
    "            else:\n",
    "                label_tls = TfmdLists(frame, label_tfms)\n",
    "                \n",
    "            tls = TfmdLists(zip(seq_tls, label_tls), [])\n",
    "            train, test = splitter(tls)\n",
    "            \n",
    "            return DataLoaders.from_dsets(tls[train], tls[test], num_workers=0).to(device)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            train, test = splitter(frame)\n",
    "            feat_tls = Datasets(frame, [seq_tfms, label_tfms],\n",
    "                               splits = (train, test))\n",
    "            \n",
    "            dls = feat_tls.dataloaders(num_workers=0).to(device)\n",
    "            \n",
    "            return dls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be easily used to create a Dataloader from any dataframe.\n",
    "\n",
    "Like so. If no label-column is provided, it assumes this is an autoencoding pre-training task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0184,  0.1971, -0.1281,  ..., -0.0300,  0.0073,  0.0132],\n",
       "         [ 0.0614,  0.2085, -0.1526,  ..., -0.0509, -0.0295, -0.0242],\n",
       "         [ 0.1123,  0.1572, -0.1147,  ..., -0.0799, -0.0502, -0.0264],\n",
       "         ...,\n",
       "         [-0.1431,  0.0607, -0.1217,  ..., -0.0705, -0.0164,  0.0204],\n",
       "         [ 0.0345,  0.2125, -0.1170,  ..., -0.0566, -0.0182,  0.0117],\n",
       "         [ 0.0395,  0.2265, -0.1417,  ..., -0.0208, -0.0214, -0.0201]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0184,  0.1971, -0.1281,  ..., -0.0300,  0.0073,  0.0132],\n",
       "         [ 0.0614,  0.2085, -0.1526,  ..., -0.0509, -0.0295, -0.0242],\n",
       "         [ 0.1123,  0.1572, -0.1147,  ..., -0.0799, -0.0502, -0.0264],\n",
       "         ...,\n",
       "         [-0.1431,  0.0607, -0.1217,  ..., -0.0705, -0.0164,  0.0204],\n",
       "         [ 0.0345,  0.2125, -0.1170,  ..., -0.0566, -0.0182,  0.0117],\n",
       "         [ 0.0395,  0.2265, -0.1417,  ..., -0.0208, -0.0214, -0.0201]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls = HFBertDataLoaders.from_df(df, tokenizer, model, \n",
    "                                label_col=None, precompute=True)\n",
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def create_bert_head(nf, n_out, lin_ftrs=None, ps=0.5, concat_pool=True, first_bn=True, bn_final=False,\n",
    "                     lin_first=False, y_range=None):\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and out `n_out` classes.\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [True]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [Flatten()]\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class ProtBertHead(Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_features = 3072, \n",
    "                 hidden_dim = 128,\n",
    "                 out_features = 'autoencoder', \n",
    "                 encoder = None,\n",
    "                 lin_ftrs = [1024], ps = 0.25):\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        if out_features == 'autoencoder':\n",
    "            self.out_features = in_features\n",
    "        else:\n",
    "            self.out_features = out_features\n",
    "        \n",
    "        if encoder is None:\n",
    "            self.encoder = create_bert_head(in_features, hidden_dim, lin_ftrs = lin_ftrs, ps=ps)\n",
    "        else:\n",
    "            self.encoder = encoder\n",
    "        \n",
    "        self.decoder = create_bert_head(self.hidden_dim, self.out_features, lin_ftrs = lin_ftrs, ps = ps)\n",
    "        \n",
    "    def re_head(self, new_out_features, lin_ftrs = [1024], ps = 0.25):\n",
    "        \n",
    "        \n",
    "        return ProtBertHead(in_features=self.in_features,\n",
    "                             hidden_dim=self.hidden_dim,\n",
    "                             out_features = new_out_features,\n",
    "                             encoder = self.encoder,\n",
    "                             lin_ftrs = lin_ftrs, ps = ps)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        \n",
    "        return decoded\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can be loaded using a ProtBert Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "#@delegates(Learner.__init__)\n",
    "def protbert_classifier_learner(dls, in_features, \n",
    "                                model = None,\n",
    "                                n_out=None,\n",
    "                                lin_ftrs=None, \n",
    "                                max_len=128, hidden_dim = 128,\n",
    "                                ps = 0.25,\n",
    "                                y_range=None, **kwargs):\n",
    "    \"Create a `Learner` with a ProtBert classifier from `dls` and `arch`.\"\n",
    "        \n",
    "    if model is None:\n",
    "        if n_out == 'autoencoder': n_out = in_features\n",
    "        if n_out is None: n_out = get_c(dls)\n",
    "        if n_out is None: n_out = in_features\n",
    "            \n",
    "        model = ProtBertHead(in_features = in_features,\n",
    "                              out_features= n_out,\n",
    "                              hidden_dim = hidden_dim,\n",
    "                              lin_ftrs = lin_ftrs, ps = ps)\n",
    "        \n",
    "    learn = Learner(dls, model, **kwargs)\n",
    "    \n",
    "    return learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often it is useful to pre-train with an autodencoder. This model makes that easy.\n",
    "\n",
    "From the top. Here is a whole set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>sample_tissue</th>\n",
       "      <th>coreceptor</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M17449</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CXCR4</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTACTTCYCKKCCFHCQVCFTKKALGISYGRKKRRQRRRAPEDSQTHQVSLPKQPAPQFRGDPTGPKESKKKVERETETHPVD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M26727</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTASNNCYCKRCCLHCQVCFTKKGLGISYGRKKRRQRRRAPQDSKTHQVSLSKQPASQPRGDPTGPKESKKKVERETETDPED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M17451</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5|CXCR4</td>\n",
       "      <td>MEPVDPRLEPWKHPGSQPKTACNNCYCKKCCYHCQVCFLTKGLGISYGRKKRRQRRGPPQGSQTHQVSLSKQPTSQPRGDPTGPKESKEKVERETETDPAVQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K02007</td>\n",
       "      <td>PBMC</td>\n",
       "      <td>CCR5|CXCR4</td>\n",
       "      <td>MEPVDPNLEPWKHPGSQPRTACNNCYCKKCCFHCYACFTRKGLGISYGRKKRRQRRRAPQDSQTHQASLSKQPASQSRGDPTGPTESKKKVERETETDPFD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M62320</td>\n",
       "      <td>blood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEPVDPNLEPWKHPGSQPTTACSNCYCKVCCWHCQLCFLKKGLGISYGKKKRKPRRGPPQGSKDHQTLIPKQPLPQSQRVSAGQEESKKKVESKAKTDRFA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession sample_tissue  coreceptor  \\\n",
       "0    M17449          PBMC       CXCR4   \n",
       "1    M26727          PBMC        CCR5   \n",
       "2    M17451          PBMC  CCR5|CXCR4   \n",
       "3    K02007          PBMC  CCR5|CXCR4   \n",
       "4    M62320         blood         NaN   \n",
       "\n",
       "                                                                                                 sequence  \n",
       "0   MEPVDPRLEPWKHPGSQPKTACTTCYCKKCCFHCQVCFTKKALGISYGRKKRRQRRRAPEDSQTHQVSLPKQPAPQFRGDPTGPKESKKKVERETETHPVD  \n",
       "1   MEPVDPRLEPWKHPGSQPKTASNNCYCKRCCLHCQVCFTKKGLGISYGRKKRRQRRRAPQDSKTHQVSLSKQPASQPRGDPTGPKESKKKVERETETDPED  \n",
       "2  MEPVDPRLEPWKHPGSQPKTACNNCYCKKCCYHCQVCFLTKGLGISYGRKKRRQRRGPPQGSQTHQVSLSKQPTSQPRGDPTGPKESKEKVERETETDPAVQ  \n",
       "3   MEPVDPNLEPWKHPGSQPRTACNNCYCKKCCFHCYACFTRKGLGISYGRKKRRQRRRAPQDSQTHQASLSKQPASQSRGDPTGPTESKKKVERETETDPFD  \n",
       "4   MEPVDPNLEPWKHPGSQPTTACSNCYCKVCCWHCQLCFLKKGLGISYGKKKRKPRRGPPQGSKDHQTLIPKQPLPQSQRVSAGQEESKKKVESKAKTDRFA  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../tutorials/HIV_tat_example.csv').dropna(subset = ['sample_tissue'])\n",
    "df['sequence'] = df['sequence'].str.strip('*')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cddddf886ed84fd58e44c9f3eaf3a5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=361.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8988c2be09493f851390ffdc88941f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa1a759b0a448da9a2e8564259b1443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=112.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb0ca863322d490394bf83b68bd083b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=86.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b50da92939f4c30a255bc47c171e65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1684058277.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Rostlab/prot_bert_bfd'\n",
    "device = 'cuda'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_dls = HFBertDataLoaders.from_df(df, tokenizer, model, \n",
    "                                     label_col=None, precompute=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.040663</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.188775</td>\n",
       "      <td>0.032776</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.144123</td>\n",
       "      <td>0.025192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.106929</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075759</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.051830</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034189</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022395</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "auto_learner = protbert_classifier_learner(dls, model.config.hidden_size*3, \n",
    "                                           n_out = 'autoencoder',\n",
    "                                           loss_func = nn.MSELoss())\n",
    "auto_learner.fit_one_cycle(50, lr_max = 0.01, cbs = [EarlyStoppingCallback(patience=1)])\n",
    "auto_learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dls = HFBertDataLoaders.from_df(df, tokenizer, model, \n",
    "                                      label_col='sample_tissue', precompute=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = df['sample_tissue'].dropna().unique()\n",
    "label_learner = protbert_classifier_learner(label_dls, None,\n",
    "                                            model= auto_learner.model.re_head(len(vocab), lin_ftrs=[64, 32]),\n",
    "                                            loss_func = nn.CrossEntropyLoss(),  metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.454245</td>\n",
       "      <td>2.484555</td>\n",
       "      <td>0.045564</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.386216</td>\n",
       "      <td>2.242213</td>\n",
       "      <td>0.436451</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.319040</td>\n",
       "      <td>2.123848</td>\n",
       "      <td>0.472422</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.240711</td>\n",
       "      <td>2.114523</td>\n",
       "      <td>0.460432</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.171865</td>\n",
       "      <td>2.051955</td>\n",
       "      <td>0.529976</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.108036</td>\n",
       "      <td>2.110823</td>\n",
       "      <td>0.570743</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.017675</td>\n",
       "      <td>1.950459</td>\n",
       "      <td>0.623501</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.945742</td>\n",
       "      <td>1.824279</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.846583</td>\n",
       "      <td>1.847966</td>\n",
       "      <td>0.628297</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.737161</td>\n",
       "      <td>1.725049</td>\n",
       "      <td>0.645084</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.624952</td>\n",
       "      <td>1.723468</td>\n",
       "      <td>0.606715</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.517625</td>\n",
       "      <td>1.909873</td>\n",
       "      <td>0.652278</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.402156</td>\n",
       "      <td>1.492369</td>\n",
       "      <td>0.628297</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.267897</td>\n",
       "      <td>1.537704</td>\n",
       "      <td>0.613909</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.168728</td>\n",
       "      <td>1.657603</td>\n",
       "      <td>0.628297</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 12: early stopping\n"
     ]
    }
   ],
   "source": [
    "label_learner.fit_one_cycle(50, lr_max = 0.001, cbs = [EarlyStoppingCallback(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.889650</td>\n",
       "      <td>1.413247</td>\n",
       "      <td>0.623501</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.858413</td>\n",
       "      <td>1.375695</td>\n",
       "      <td>0.613909</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.822202</td>\n",
       "      <td>1.377387</td>\n",
       "      <td>0.613909</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.791884</td>\n",
       "      <td>1.411415</td>\n",
       "      <td>0.630695</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement since epoch 1: early stopping\n"
     ]
    }
   ],
   "source": [
    "label_learner.unfreeze()\n",
    "label_learner.fit_one_cycle(50, lr_max = 0.001, cbs = [EarlyStoppingCallback(patience=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
